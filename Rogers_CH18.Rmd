---
title: "Rogers_CH18"
author: "Alex Rogers"
date: "3/26/2022"
output: html_document
---

### How Does it Work?

##### 1.	In the Event Studies chapter we estimated the effect of something that occurs at a specific time by just comparing before-event to after-event, without really using a control group. What assumption is made by no-control-group event studies that we don’t have to make with difference-in-differences?

**So we didn't read this chapter, but based on what I've learned about difference in difference, I would guess that by not using a control group in event studies, you make the assumption that the single group did not have any backdoors between some variable and the outcome which might have change pre and post treatment. That is, you're assuming that the only thing causing the outcome is the treatment (assuming you've controlled for what you can).**

**With difference in difference, we don't have to make that assumption because we have a comprable group which we can use to compare in order to see if there was change post treatment that wasn't related to the treatment. Though difference in difference still has to make other assumptions (like parallel trends)**

##### 2.	Which of the following potential back doors is controlled for by comparing the treated group to a control group?

a.	The treated group may be following a trend, unique to the group, that would make the outcome change from before-treatment to after-treatment anyway

**b.	There may be events affecting everyone that would change the outcome from before-treatment to after-treatment anyway**

c.	There may be differences in typical outcome levels between the treated group and the untreated group

d.	The decision to treat the treated group, rather than some other group, may be based on factors that are related to the outcome

##### 3.	Consider a treatment and control group. Looking only at the pre-treatment period, they have exactly the same outcomes (zero gap between them in each period).

a.	Despite having exactly the same outcomes pre-treatment, it happens to be the case that parallel trends is violated for these two groups. How is this possible? Explain what it means for parallel trends to be violated in this case, or give an example of how it could be violated.

**Maybe something happens to the control group at the time of treatment which effects the outcome variable. For example, you're interested in the effect of frequency of trash collection on littering. So you look at a treated and untreated city which have similar rates of littering pre-treatment. The treatment introduced into the treated city is the introduction of more garbage collection routes. At the time that treatment is introduced, the untreated city happens to pass legislation more heavily sanctioning littering. Thus parallel trends in the post period does not hold**

b.	If we estimate the causal effect in this case using difference-in-differences, even though parallel trends is violated, how much would our effect be off by? (note you won’t be able to give a specific number)

**In this example our estimate of the effect of the program in the treated city would likely be decreased. We would likely see a decrease in littering in the control city, which would make the strength of our comparison weaker.**

##### 4.	Consider the below graph showing the average outcome for treated and control groups in the leadup to treatment (indicated by the dashed line), and also after treatment.

![](/Users/alexr/Desktop/4.png)


a.	Based on the prior trend, does it seem likely that parallel trends holds in this instance?

**No, the relationship between the untreated and treated group is not constant in the prior trend**

b.	If we estimate difference-in-differences anyway, are we likely to overestimate the actual causal effect, underestimate it, or get it right on average?

**Difference in difference is (TreatedPost - TreatedPre) - (UntreatedPost - UntreatedPre). So here we would likely underestimate the effect.**

##### 5.	In mid-2020, during the COVID-19 pandemic, different countries pursued different courses of action. Some locked down fully, imposing harsh penalties to most people for leaving the house outside certain proscribed times. Some were looser and only suggested staying at home, and some had hardly any restrictions at all. You notice that COVID rates tend to spike dramatically in different countries at seemingly-random times, and want to know if certain restrictions helped.

##### From March through May 2020, US and Canada COVID case rates followed similar trends (US rates were higher, but the trends were similar). You want to look at the effect of COVID restrictions enacted in Canada in late May 2020 on case rates. Is DID, with the US as a control group, a good way to estimate this effect? If not, what concerns would you have about this research design?

**So the pre-period sounds good. If the rates in Canada and the US followed similar trends, even with different intercepts, then difference in difference is likely a good approach. The last sentence of the first paragraph is confusing though. If we know we can expect random spikes in different countries in the post-period, that might introduce some issues. Though if we know they are actually "random" and effect different countries the same, then we are probably okay. I think the US and Canada are probably roughly comparable around this topic generally (that is that time effects the US and Canada in similar ways regarding COVID rates**

##### 6.	Consider the below table of mean outcomes, and calculate the difference-in-difference effect of treatment. Write out the equation you used to calculate it (i.e. show how the four numbers in the table are combined to get the estimate)

![](/Users/alexr/Desktop/6.png)


**Treated difference: 9 - 5 = 4**

**Untreated difference: 7.5 - 6 = 1.5**

**Difference in difference: 4 - 1.5 = 2.5**

### How is it Performed?

##### 1.	You are planning to estimate whether voter-protection laws increase voter turnout. You note that, in 2015, a lot of new voter-protection laws were enacted in some provinces but not in others. Conveniently, no new laws were enacted in 2012, 2014, or 2016, so you decide to use 2012 and 2014 as your “before” periods and 2016 as “after”. 

##### a.	Which of the following best describes what you’d want to regress state-and-year level “voter turnout” measures on?

  i.	An indicator for whether the state is treated, and an indicator for whether the year is 2016.

  ii.	A set of fixed effects for state, and a set of fixed effects for year.

  iii.	An indicator for whether the state is treated, a set of fixed effects for year, and an indicator for whether the state is currently treated.

  **iv.	A set of fixed effects for state, and for year, and an interaction between “is 2016” and “is a treated state”.**

  v.	This design should not be estimated using a regression.

b.	Unless you chose the final option in the previous question, specify which coefficient in that regression would give you the DID estimate.

**The interaction term**

##### 2.	You are looking at a difference-in-difference design to estimate the effect of providing laptops to school children on their test scores. Look at the below regression output, in which “Treated” is an indicator that the school received laptops in 2008 as part of a new program (the untreated group did not receive any laptops until years after the sample window for this study ended), and “After” is an indicator for being after the year 2008.

##### Using the table, fill in the blanks in the sentence “Assuming that **parallel trends holds**, the effect of laptops on test scores was **5.034 in the treatment group**, and this effect **was** statistically significant at the 95% level.”

![](/Users/alexr/Desktop/7.png)

##### 3.	A standard “prior trends” test might estimate a regression using the model Y= β_0+β_1 t+β_2 Treated+β_3 t×Treated+ε (only using data from before-treatment), where t is a time variable, Treated is an indicator for being in the treated group, and Y is an outcome variable, and look for a large/significant estimate of β_3. Explain why this test is performed, and specifically what it shows.

**This test is performed to make sure that the treatment effect is causing the change in Y we're interested in. What this does is simulate an event where the treated group received the treatment before the actual treatment time. In this case we should expect that there is no effect, if we do observe an effect, we might have an issue with parallel trends**

##### 4.	Consider the below graph with estimates from a dynamic difference-in-differences model for a treatment that occurs between periods 4 and 5, with 95% confidence intervals shown.
 
![](/Users/alexr/Desktop/8.png) 
 
a.	What about this graph might make us concerned about our identification assumptions?

**The effect of the treatment is very strong as first, then regresses toward the mean. If we were interested in difference in difference with a two-way fixed effects model, we might miss some important details by measuring the overall after effect, which is why it might make sense to use a dynamic model. From an implementation perspective, this graph seems to indicate that the intervention introduces immediate change but not long-lasting change.**

b.	Ignoring any concerns we have, what would we say is the effect of treatment on Y in this case? (note the height of the line in period 5 is about 3, in period 6 is about 1, and in period 7 is about .5).

**Sort of the same as how I answered the end of the last question, the effect is strong but diminshes rapidly over time**

##### 5.	Chapter 18.2.5 points out a problem with two-way fixed effects in cases where treatment is not all assigned at the same time, but rather different groups get treated at different times (a “rollout” design). In these designs, two-way fixed effects treats “already-treated” units, who were treated in earlier periods, as “control” units, as though they hadn’t gotten treated at all. 

##### However, there’s nothing theoretically wrong about using an already-treated unit as a control; the DID assumptions don’t require that the control group be untreated, just that the gap between treated and control doesn’t change when the treated group’s treatment goes into effect. Why are we so concerned, then, about using an already-treated group as a control? You can answer generally, or use as an example a DID with only two groups – an already-treated group and a newly-treated group. 

##### (hint: to do the example, try assuming the treatment only has an effect for the single period after treatment, and the already-treated group is treated exactly one period before the treated group)

**By using an already treated group in the control, some of the estimate of treatment effect on the new group getting the treatment will be diminished**


### Coding

```{r}

library(lubridate)
library(tidyverse)
library(fixest)
library(modelsummary)



```




##### 1. In this assignment we will be walking through a very simple application of difference-in-differences that comes from Peter Nencka. In particular, it seemed that the beginning of the COVID-19 pandemic led to a brief craze for homemade sourdough bread, as people had to stay home, and stores were out of yeast (sourdough can be made at home using yeast from the air and does not require store-bought yeast). We will be estimating whether COVID lockdowns actually increased interest in sourdough bread, 

We will be measuring interest in sourdough bread using Google Trends data in the USA. Google Trends tracks the popularity of different search terms over time. We will be comparing the popularity of the search term "sourdough" against the control groups: the search terms "cereal," "soup," and "sandwich," the popularity of which we suspect might not have been meaningfully affected by COVID lockdowns.

Load the data set `sourdough_trends.csv` and look through the data. In R or Python, save the dataset as `sr`.

Then, limit the data to just the variables of interest: `date`, `hits` (the Google Trends index), and `keyword`, the search term we're examining.

Finally, convert the "date" variable to a usable date.

*Language-specific instructions*:

- In R, `date` should be automatically read in as a date-time by `read_csv`. This can be converted to a `date` object using `as.Date()`, or `ymd()` from the **lubridate** package. I might recommend doing the **lubridate** approach just because it's a great package to get used to, and it may come in handy later in the assignment.


```{r}

sr <- read.csv("https://raw.githubusercontent.com/NickCH-K/TheEffectAssignments/main/sourdough_trends.csv")
sr <- sr |> 
  select(date, hits, keyword) |> mutate(date = date(sr$date))
  

```


##### 2. Make a line graph with `date` on the x-axis and `hits` on the y-axis, with a separate line for each `keyword`. Also add a vertical line for the "start of the pandemic" which we'll decide for our purposes is March 15, 2020.

*Language-specific instructions*:

- In R, you can use `ggplot()` with a `geom_line()` to graph the Apple line,  using `color = keyword` to graph each keyword separately. Add to that a `geom_vline(aes(xintercept = eventdate))` where `eventdate` is a date object, which you can create using `as.Date('YYYY-MM-DD')`. 



```{r}

eventdate <- as.Date('2020-03-15')
ggplot(data = sr, aes(x = date, y = hits, color=keyword))+
  geom_line()+
  geom_vline(aes(xintercept = eventdate))


```


##### 3. Looking at your graph from problem 2, comment on (a) whether it looks like the lockdown had an effect on the popularity of sourdough, (b) the shape that effect takes (i.e. is it a permanent increase in popularity? Temporary?), (c) whether you might be concerned about any of the control groups we've chosen

(a) There was definitely an increase in popularity of sourdough after lockdown, and it seems like that increase may not have been present in the control groups (though it's hard to say visually with so much info on the graph). I'd be weary of saying that lockdown **caused** the increase at this point.

(b) It looks like an immediate effect that reduced over time.

(c) I'm concerned about the controls without the graph. Sourdough and soup and sandwich might be different categories for what we're interested in. You make a soup or a sandwich, you bake sourdough. Better comparison categories might be "rye" or "whole wheat", though with this data you'd want those to be "rye bread" or "whole wheat bread". Or maybe the control should be "how to make(cereal, sandwich, sourdough)". Regarding the graph, soup is the main control I'd be worried about. The other three seem to be trending steadily, where soup seems to be trending downward in the pre-data.

##### 4. Create a "Treated" indicator that's equal to 1 for sourdough and 0 otherwise (or True/False, either way). Do a test of whether the prior trends (keeping March 15 as the "treatment date") differ between the treated and control groups, using a linear trend and doing a statistical significance test at the 95% level. Then, if you were concerned about any of the control groups in question 3c, drop any you were concerned about (and keep them dropped for the rest of the assignment) and rerun the test.


```{r}
#creating treatment dummy
sr <- sr |> 
  mutate(treated = keyword == 'sourdough' &
           date >= eventdate)
  


```

```{r}

prsr <- sr |> 
  filter(date < eventdate)

```

```{r}

m1 <- lm(hits ~ date + keyword + date*keyword,
         data = prsr)


```



```{r}

msummary(m1, stars = TRUE)


```
The soup keyword is statistically significant, so I will drop it.

```{r}

prsr2 <- prsr |> 
  filter(keyword !="soup")


```


```{r}

#running parallel trends again without soup

nsoupm1 <- lm(hits ~ date + keyword + date*keyword,
         data = prsr2)

```

```{r}

msummary(nsoupm1, stars = TRUE)


```

**SANDWICHES!**

```{r}

prsr3 <- prsr2 |> 
  filter(keyword !="sandwich")


```


```{r}

soupsandm1 <- lm(hits ~ date + keyword + date*keyword,
         data = prsr3)


```

```{r}

msummary(soupsandm1, stars = TRUE)


```









##### Write a line commenting on whether you can reject equal prior trends in your model(s).


**After removing soup and sandwich we don't need to reject equal trends in the model.**

```{r}

# dropping soup and sandwiches for the rest of the assignment

sr2 <- sr |> filter(keyword !="soup" & keyword !="sandwich")

```


##### 5. Create a `month` variable by shifting the `date` variable back 15 days (so that the treatment day is the first day of the month) and then taking the month of the resulting date. Also create an `After` variable equal to 1/0 (or True/False) if the date is March 15 or afterwards.

Then, take a look at the values of `month` you get and how they line up with `date`, and subtract a number from `month` so that the last period just before treatment (Feb 16-Mar 14) is 0. (Also, change the Jan 1-14 month so it's one less than the Jan 15-Feb 14 month)

Then, use two-way fixed effects to estimate the difference-in-difference estimate of the effect of lockdown on sourdough popularity with `keyword` and `month` fixed effects, and standard errors clustered at the `keyword` level.

*Language-specific instructions*:

- In R, load the **lubridate** package if you haven't already. You can then use `-days()` to subtract days from the date, and `month()` to get the month from the date. Then use `feols()` from **fixest** to estimate the model.

```{r}

#making the first of each month the 15th
sr2 <- sr2 |> 
  mutate(month = month(date-days(14)))


```

```{r}

#creating binary variable for after 03/15/2020
sr2 <- sr2 |> 
  mutate(after = date>= eventdate)

```

```{r}

#making march 15 2020 month 0
sr2 <- sr2 |> mutate(month = month-02)


```

```{r}

#fixing month ordering (thanks fatima)

sr2 <- sr2 |> 
  mutate(month = if_else(month > 9, -2, month))


```




```{r}

#fixed effects for DID of lockdown on sourdough with keyword and month fixed effects

m2 <- feols(hits ~ treated | keyword + month,
      data = sr2)
msummary(m2, stars = TRUE)

```

**So lockdown did have a statistically significant effect on sourdough**


###### 6. Now, let's allow the effect to be dynamic over time. Estimate a difference-in-difference model allowing the effect to differ by month (using `month = 0` as a reference period), with standard errors clustered at the keyword level, and show the results.

```{r}

sr2 <- sr2 |> 
  mutate(sourdough = keyword == 'sourdough')


```


```{r}

m3 <- feols(hits ~ i(month, sourdough, ref = 0) | keyword + month,
            data = sr2)


```


##### 7. Make a graph demonstrating the results of your dynamic difference-in-differences model. Describe both what the effect looks like and also whether this graph gives you any concerns about prior trends violations.


```{r}

coefplot(m3)


```

The graph indicates that there are changes along the after period. There was a strong spike at the beginning of the pandemic, which decreased over time. This makes logical sense.
